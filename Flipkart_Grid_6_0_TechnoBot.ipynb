{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PwP6xKYW7ma"
      },
      "source": [
        "#Flipkart Grid 6.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnSlzfmVB1JU"
      },
      "outputs": [],
      "source": [
        "!pip install easyocr\n",
        "!apt-get update && apt-get install -y libzbar0\n",
        "!pip install pyzbar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IM6XVCX7XDDc"
      },
      "source": [
        "###Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iG_VEs0VGYE5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports and function definitions\n",
        "\n",
        "# For running inference on the TF-Hub module.\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# For downloading the image.\n",
        "import matplotlib.pyplot as plt\n",
        "import tempfile\n",
        "from six.moves.urllib.request import urlopen\n",
        "from six import BytesIO\n",
        "\n",
        "# For drawing onto the image.\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from PIL import ImageColor\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageOps\n",
        "\n",
        "# For measuring the inference time.\n",
        "import time\n",
        "\n",
        "import easyocr\n",
        "import cv2\n",
        "import re\n",
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "\n",
        "import re\n",
        "from datetime import datetime\n",
        "from pyzbar.pyzbar import decode\n",
        "\n",
        "# Print Tensorflow version\n",
        "print(tf.__version__)\n",
        "\n",
        "# Check available GPU devices.\n",
        "print(\"The following GPU devices are available: %s\" % tf.test.gpu_device_name())"
      ],
      "metadata": {
        "id": "_uNcW7Gga2-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Function for Displaying Image"
      ],
      "metadata": {
        "id": "o62BcFtm86pJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9IwDpOtpIHW"
      },
      "outputs": [],
      "source": [
        "def display_image(image):\n",
        "  fig = plt.figure(figsize=(20, 15))\n",
        "  plt.grid(False)\n",
        "  plt.imshow(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Function for downloading image from url"
      ],
      "metadata": {
        "id": "dn63hFHr8-gr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-Vpq5McUYYq"
      },
      "outputs": [],
      "source": [
        "def download_and_resize_image(url, new_width=256, new_height=256, display=False):\n",
        "  _, filename = tempfile.mkstemp(suffix=\".jpg\")\n",
        "  response = urlopen(url)\n",
        "  image_data = response.read()\n",
        "  image_data = BytesIO(image_data)\n",
        "  pil_image = Image.open(image_data)\n",
        "  pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.LANCZOS)\n",
        "  pil_image_rgb = pil_image.convert(\"RGB\")\n",
        "  pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n",
        "  print(\"Image downloaded to %s.\" % filename)\n",
        "  if display:\n",
        "    display_image(pil_image)\n",
        "  return filename"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Function for draw bounding boxes"
      ],
      "metadata": {
        "id": "DYv4EKX99GG_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8P2I702uUYut"
      },
      "outputs": [],
      "source": [
        "def draw_bounding_box_on_image(image,ymin,xmin,ymax,xmax,color,font,thickness=4,display_str_list=()):\n",
        "\n",
        "  \"\"\"Adds a bounding box to an image.\"\"\"\n",
        "  draw = ImageDraw.Draw(image)\n",
        "  im_width, im_height = image.size\n",
        "  (left, right, top, bottom) = (xmin * im_width, xmax * im_width, ymin * im_height, ymax * im_height)\n",
        "  draw.line([(left, top), (left, bottom), (right, bottom), (right, top),(left, top)], width=thickness, fill=color)\n",
        "\n",
        "  # If the total height of the display strings added to the top of the bounding\n",
        "  # box exceeds the top of the image, stack the strings below the bounding box\n",
        "  # instead of above.\n",
        "  display_str_heights = [font.getbbox(ds)[3] for ds in display_str_list]\n",
        "\n",
        "  # Each display_str has a top and bottom margin of 0.05x.\n",
        "  total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
        "\n",
        "  if top > total_display_str_height:\n",
        "    text_bottom = top\n",
        "  else:\n",
        "    text_bottom = top + total_display_str_height\n",
        "\n",
        "  # Reverse list and print from bottom to top.\n",
        "  for display_str in display_str_list[::-1]:\n",
        "    bbox = font.getbbox(display_str)\n",
        "    text_width, text_height = bbox[2], bbox[3]\n",
        "    margin = np.ceil(0.05 * text_height)\n",
        "    draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n",
        "                    (left + text_width, text_bottom)],\n",
        "                   fill=color)\n",
        "    draw.text((left + margin, text_bottom - text_height - margin),\n",
        "              display_str,\n",
        "              fill=\"black\",\n",
        "              font=font)\n",
        "    text_bottom -= text_height - 2 * margin"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Function for returning coordinates"
      ],
      "metadata": {
        "id": "HJ9MzdYY9Lun"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lN9vYdQ2U9rp"
      },
      "outputs": [],
      "source": [
        "def draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.1):\n",
        "\n",
        "  \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n",
        "  colors = list(ImageColor.colormap.values())\n",
        "\n",
        "  try:\n",
        "    font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\", 25)\n",
        "  except IOError:\n",
        "    print(\"Font not found, using default font.\")\n",
        "    font = ImageFont.load_default()\n",
        "\n",
        "  coordinates = []\n",
        "  for i in range(min(boxes.shape[0], max_boxes)):\n",
        "    if scores[i] >= min_score:\n",
        "      ymin, xmin, ymax, xmax = tuple(boxes[i])\n",
        "      coordinates.append((xmin, ymin, xmax, ymax))\n",
        "      display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"), int(100 * scores[i]))\n",
        "      color = colors[hash(class_names[i]) % len(colors)]\n",
        "      image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n",
        "      draw_bounding_box_on_image(image_pil, ymin, xmin, ymax, xmax, color, font, display_str_list=[display_str])\n",
        "      np.copyto(image, np.array(image_pil))\n",
        "\n",
        "  return image, coordinates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFrcVGukVUwM"
      },
      "outputs": [],
      "source": [
        "module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\" #@param [\"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\", \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"]\n",
        "\n",
        "detector = hub.load(module_handle).signatures['default']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Function for loading Image as tf.tensor"
      ],
      "metadata": {
        "id": "tRaWYY2p9W4y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znW8Fq1EC0x7"
      },
      "outputs": [],
      "source": [
        "def load_img(path):\n",
        "  img = tf.io.read_file(path)\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  return img"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Cropping Image"
      ],
      "metadata": {
        "id": "DNYV0NR89erv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gt4surLL_DBJ"
      },
      "outputs": [],
      "source": [
        "# Function to crop image using center coordinates and dimensions\n",
        "def crop_image(image_path, xmin, ymin, xmax, ymax):\n",
        "    # Load the image\n",
        "    image = cv2.imread(image_path)\n",
        "    cropped_image = image[ymin:ymax, xmin:xmax]\n",
        "    display_image(cropped_image)\n",
        "\n",
        "    return cropped_image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Parsing date into standard format"
      ],
      "metadata": {
        "id": "Q4JEnzNW9irL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBosm0voJbay"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "# Dictionary to map month names/abbreviations to numbers\n",
        "months = {\n",
        "    \"jan\": \"01\", \"feb\": \"02\", \"mar\": \"03\", \"apr\": \"04\", \"may\": \"05\", \"jun\": \"06\",\n",
        "    \"jul\": \"07\", \"aug\": \"08\", \"sep\": \"09\", \"oct\": \"10\", \"nov\": \"11\", \"dec\": \"12\",\n",
        "    \"january\": \"01\", \"february\": \"02\", \"march\": \"03\", \"april\": \"04\", \"may\": \"05\",\n",
        "    \"june\": \"06\", \"july\": \"07\", \"august\": \"08\", \"september\": \"09\", \"october\": \"10\",\n",
        "    \"november\": \"11\", \"december\": \"12\"\n",
        "}\n",
        "\n",
        "def parse_date(date_str):\n",
        "    # Patterns for different date formats\n",
        "    patterns = [\n",
        "        (r\"^\\d{1,2}/\\d{1,2}/\\d{4}$\", \"%d/%m/%Y\"),     # dd/mm/yyyy\n",
        "        (r\"^\\d{1,2}/\\d{4}$\", \"%m/%Y\"),                # mm/yyyy\n",
        "        (r\"^\\d{1,2}/\\d{2}$\", \"%m/%y\"),                # mm/yy\n",
        "        (r\"^\\d{1,2}-\\d{1,2}-\\d{4}$\", \"%d-%m-%Y\"),     # dd-mm-yyyy\n",
        "        (r\"^\\d{1,2}-\\d{4}$\", \"%m-%Y\"),                # mm/yyyy\n",
        "        (r\"^\\d{1,2}-\\d{2}$\", \"%m-%y\"),                # mm/yy\n",
        "        (r\"^\\d{2}/\\d{2}/\\d{2}$\", \"%d/%m/%y\"),         # dd/mm/yy\n",
        "        (r\"^\\d{2}\\d{2}\\d{2}$\", \"%d%m%y\"),             # ddmmyy\n",
        "        (r\"^\\d{2}\\d{2}\\d{4}$\", \"%d%m%Y\"),             # ddmmyyyy\n",
        "        (r\"^(\\d{1,2})\\s+([A-Za-z]+)\\s+(\\d{4})$\", None),  # dd Month yyyy (full or abbreviated)\n",
        "        (r\"^(?P<month>[a-zA-Z]{3,9})[\\. ]?'?(?P<year>\\d{2,4})$\", None)  # month/yyyy or month yy with . or space\n",
        "    ]\n",
        "\n",
        "    for pattern, fmt in patterns:\n",
        "        match = re.match(pattern, date_str, re.IGNORECASE)\n",
        "        if match:\n",
        "            if fmt:  # For direct datetime formatting\n",
        "                parsed_date = datetime.strptime(date_str, fmt)\n",
        "                return parsed_date.strftime(\"%d/%m/%Y\")\n",
        "            else:  # Handle custom formats like dd Month yyyy or month/yy\n",
        "                if \"month\" in match.groupdict():\n",
        "                    month = match.group(\"month\").lower()  # Get month in lower case for mapping\n",
        "                    year = match.group(\"year\")\n",
        "                    if len(year) == 2:\n",
        "                        year = f\"20{year}\"  # Convert 'yy' to '20yy'\n",
        "                    month_num = months.get(month[:3])  # Get first 3 letters for matching\n",
        "                    if month_num:\n",
        "                        return f\"15/{month_num}/{year}\"  # Default day to 15 if not specified\n",
        "                else:\n",
        "                    day = match.group(1)\n",
        "                    month = match.group(2).lower()  # Get month in lower case for mapping\n",
        "                    year = match.group(3)\n",
        "                    if len(year) == 2:\n",
        "                        year = f\"20{year}\"  # Convert 'yy' to '20yy'\n",
        "                    month_num = months.get(month)  # Get month number from dictionary\n",
        "                    if month_num:\n",
        "                        return f\"{day}/{month_num}/{year}\"\n",
        "\n",
        "    raise ValueError(f\"Invalid date format: {date_str}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZR3NvXKNWb4h"
      },
      "outputs": [],
      "source": [
        "def parse_date1(date_str):\n",
        "    # Parse the date string to a datetime object\n",
        "    try:\n",
        "        return datetime.strptime(date_str, '%d/%m/%Y')  # Adjust format if necessary\n",
        "    except ValueError:\n",
        "        return datetime.strptime(date_str, '%m/%d/%Y')  # Try another format if needed"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Pre-Process Image"
      ],
      "metadata": {
        "id": "p2mboKvb9pgn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-boK256YWTSM"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(image):\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply noise reduction\n",
        "    noise_reduced = cv2.fastNlMeansDenoising(gray, None, 30, 7, 21)\n",
        "\n",
        "    return noise_reduced"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Extracting text using OCR"
      ],
      "metadata": {
        "id": "aFZ82Vvy9tgS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5K9v8LsWYP9"
      },
      "outputs": [],
      "source": [
        "def extract_text_easyocr(image_path):\n",
        "    reader = easyocr.Reader(['en'])\n",
        "    result = reader.readtext(image_path,detail=0)\n",
        "    return \"[]\".join(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Extracting dates and mrp using regex patterns"
      ],
      "metadata": {
        "id": "qS0jurr1-hgl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taLWZnyPWf5I"
      },
      "outputs": [],
      "source": [
        "def extract_dates_and_mrp(text):\n",
        "\n",
        "    date_pattern = r'\\b(\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4})\\b'\n",
        "    mrp_pattern = r'\\b(?:MRP|mrp|M\\.R\\.P|MAX\\.? RETAIL PRICE|price|Rs|₹)\\s*[:\\-]?\\s*([₹$£]?[\\d,]+(?:\\.\\d{1,2})?)\\b'\n",
        "\n",
        "    duration_pattern = r'\\b(?:best before|valid until)\\s*(\\d+)\\s*(days?|months?|years?)\\b'\n",
        "\n",
        "    lines = text.split('[]')\n",
        "    pp = []\n",
        "\n",
        "    for i in lines:\n",
        "        try:\n",
        "            pp.append(parse_date(i))\n",
        "        except:\n",
        "            pp.append(i)\n",
        "    ppp = \" \".join(pp)\n",
        "    # Find all date and MRP matches in the text\n",
        "    dates = re.findall(date_pattern, ppp, re.IGNORECASE)\n",
        "    mrp_matches = re.findall(mrp_pattern, ppp, re.IGNORECASE | re.DOTALL)\n",
        "    # Initialize variables for identified dates\n",
        "    expiry_date = None\n",
        "    manufactured_date = None\n",
        "\n",
        "    # Identify context for dates\n",
        "    lines = ppp.split('\\n')\n",
        "    for line in lines:\n",
        "        if any(keyword in line.lower() for keyword in ['valid until', 'best before','expires in']):\n",
        "            # Check for duration related to expiry\n",
        "            duration_match = re.search(duration_pattern, line, re.IGNORECASE)\n",
        "            if duration_match:\n",
        "                num_days = int(duration_match.group(1))\n",
        "                time_unit = duration_match.group(2).lower()\n",
        "                # Calculate the expiry date based on the duration\n",
        "                base = parse_date1(dates[0])\n",
        "                manufactured_date = base.strftime('%d/%m/%Y')\n",
        "                if 'day' in time_unit:\n",
        "                    expiry_date = (base + relativedelta(days=num_days)).strftime('%d/%m/%Y')\n",
        "                elif 'month' in time_unit:\n",
        "                    expiry_date = (base + relativedelta(months=num_days)).strftime('%d/%m/%Y')\n",
        "                elif 'year' in time_unit:\n",
        "                    expiry_date = (base + relativedelta(years=num_days)).strftime('%d/%m/%Y')\n",
        "            else:\n",
        "                expiry_date_matches = re.findall(date_pattern, line, re.IGNORECASE)\n",
        "                if expiry_date_matches:\n",
        "                    expiry_date = parse_date(expiry_date_matches[0])\n",
        "\n",
        "        if any(keyword in line.lower() for keyword in ['exp', 'Exp Date', 'use by']):\n",
        "            expiry_date_matches = re.findall(date_pattern, line, re.IGNORECASE)\n",
        "            if expiry_date_matches:\n",
        "                expiry_date = expiry_date_matches[0]\n",
        "        if any(keyword in line.lower() for keyword in ['mfd', 'Mfg Date', 'mfg.date']):\n",
        "            manufactured_date_matches = re.findall(date_pattern, line, re.IGNORECASE)\n",
        "            if manufactured_date_matches:\n",
        "                manufactured_date = manufactured_date_matches[0]\n",
        "    if len(dates)==1:\n",
        "        if not expiry_date:\n",
        "            expiry_date = dates[0]\n",
        "    if len(dates)==2:\n",
        "        date1 = parse_date1(dates[0])\n",
        "        date2 = parse_date1(dates[1])\n",
        "        if date1 > date2:\n",
        "            expiry_date = date1.strftime('%d/%m/%Y')\n",
        "            manufactured_date = date2.strftime('%d/%m/%Y')\n",
        "        elif date1 < date2:\n",
        "            expiry_date = date2.strftime('%d/%m/%Y')\n",
        "            manufactured_date = date1.strftime('%d/%m/%Y')\n",
        "    return {\n",
        "        \"expiry_date\": expiry_date,\n",
        "        \"manufactured_date\": manufactured_date,\n",
        "        \"mrp\": mrp_matches[0] if mrp_matches else None}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Function for extracting information from QR code or bar code"
      ],
      "metadata": {
        "id": "PxAke3dD-mkH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXuazIkobt-i"
      },
      "outputs": [],
      "source": [
        "#Reading QR Code\n",
        "from pyzbar.pyzbar import decode\n",
        "\n",
        "def extract_qr_barcode(image):\n",
        "    \"\"\"Extract QR and barcode data from the image.\"\"\"\n",
        "    preprocessed_image = preprocess_image(image)\n",
        "    decoded_objects = decode(preprocessed_image)\n",
        "    qr_barcode_data = []\n",
        "\n",
        "    for obj in decoded_objects:\n",
        "        data = obj.data.decode('utf-8')\n",
        "        qr_barcode_data.append({\n",
        "            'type': obj.type,\n",
        "            'data': data,\n",
        "            'bounding_box': obj.rect\n",
        "        })\n",
        "\n",
        "    return qr_barcode_data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E84ekrsGWyZX"
      },
      "outputs": [],
      "source": [
        "def process_image(image_path, use_easyocr=False):\n",
        "\n",
        "    # Preprocess the image\n",
        "    preprocessed_image = preprocess_image(image_path)\n",
        "    # Extract text using the selected OCR tool\n",
        "    text = extract_text_easyocr(preprocessed_image)\n",
        "    # Post-process the extracted text to find relevant information\n",
        "    result = extract_dates_and_mrp(text)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Running Model for object detection"
      ],
      "metadata": {
        "id": "PcUpf847-1N-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwGJV96WWBLH"
      },
      "outputs": [],
      "source": [
        "def run_detector(detector, path):\n",
        "  img = load_img(path)\n",
        "\n",
        "  converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
        "\n",
        "  start_time = time.time()\n",
        "  result = detector(converted_img)\n",
        "  end_time = time.time()\n",
        "\n",
        "  result = {key:value.numpy() for key,value in result.items()}\n",
        "\n",
        "  print(\"Inference time: \", end_time-start_time)\n",
        "  image_with_boxes, coords = draw_boxes(\n",
        "      img.numpy(), result[\"detection_boxes\"],\n",
        "      result[\"detection_class_entities\"], result[\"detection_scores\"])\n",
        "\n",
        "  img_pil = Image.fromarray(np.uint8(img.numpy())).convert(\"RGB\")\n",
        "  img_width, img_height = img_pil.size\n",
        "\n",
        "  # display_image(image_with_boxes)\n",
        "  reader = easyocr.Reader(['en'])\n",
        "  for i in range(len(coords)):\n",
        "    # Calculate pixel coordinates\n",
        "    xmin = int(coords[i][0] * img_width)\n",
        "    ymin = int(coords[i][1] * img_height)\n",
        "    xmax = int(coords[i][2] * img_width)\n",
        "    ymax = int(coords[i][3] * img_height)\n",
        "\n",
        "    # Crop the image using the pixel coordinates\n",
        "    cropped_image = crop_image(path, xmin, ymin, xmax, ymax)\n",
        "    result = process_image(cropped_image)\n",
        "    print(f\"Detected text in cropped area {i}: {result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rubdr2JXfsa1"
      },
      "outputs": [],
      "source": [
        "def detect_img(image_url):\n",
        "  # image_path = download_and_resize_image(image_url, 640, 480)\n",
        "  run_detector(detector, image_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Image Input"
      ],
      "metadata": {
        "id": "HS0PtbIp-9KS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxGjekNn8VLE"
      },
      "outputs": [],
      "source": [
        "image_path = f'/content/0.jpg' #Enter image path here\n",
        "image = cv2.imread(image_path)\n",
        "detect_img(image_path)\n",
        "qr_result = extract_qr_barcode(image)\n",
        "if qr_result:\n",
        "  print(\"QR/Bar Code Data : \",qr_result[0]['data'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}